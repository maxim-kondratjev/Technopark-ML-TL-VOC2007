{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11876,
     "status": "ok",
     "timestamp": 1542553600065,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "zrZs-4DcXW9O",
    "outputId": "b1e349cd-8287-4554-d6a9-19eca8ace829"
   },
   "outputs": [],
   "source": [
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anY77OYKXlyU"
   },
   "outputs": [],
   "source": [
    " !kill -9 -1 #(перезагрузка collab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31660,
     "status": "ok",
     "timestamp": 1542553637602,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "XbXzx6PPzlw9",
    "outputId": "380434ab-a1cf-409d-f785-3929d2005b25"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 756,
     "status": "ok",
     "timestamp": 1542554862460,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "-n5ASkrIw9mz",
    "outputId": "a8d0ac00-a334-4ffd-f8e4-8d94ba6baaaf"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_classes = 20\n",
    "model.fc = nn.Linear(in_features=512, out_features=num_classes)\n",
    "nn.init.xavier_uniform_(model.fc.weight)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28005,
     "status": "ok",
     "timestamp": 1542554897406,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "wCCOEuAow9m8",
    "outputId": "1082565b-0a11-4aaa-dc50-fc34686ef310"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262080
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44182,
     "status": "ok",
     "timestamp": 1542554942960,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "oWMiahTby9PV",
    "outputId": "a70888f2-2ed3-450e-eb8e-e1c3a1fb69ff"
   },
   "outputs": [],
   "source": [
    "!ls -la /gdrive/My\\ Drive/ML\n",
    "!cp /gdrive/My\\ Drive/ML/VOC2007.tar.gz .\n",
    "!ls .\n",
    "!tar -xvf VOC2007.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1jysm2rw9m_"
   },
   "outputs": [],
   "source": [
    "from  torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "IMAGE_FOLDER_ROOT = 'sample_data/VOC2007/VOC2007'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "data_train = ImageFolder(IMAGE_FOLDER_ROOT+'/trainval',transform=transforms.Compose([transforms.Resize(224),transforms.RandomCrop(224),transforms.ToTensor(),normalize]))\n",
    "data_test = ImageFolder(IMAGE_FOLDER_ROOT+'/test',transform=transforms.Compose([transforms.Resize(224),transforms.RandomCrop(224),transforms.ToTensor(),normalize]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 80233,
     "status": "ok",
     "timestamp": 1542554986408,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "JSMNLRXH3ZYE",
    "outputId": "debf47a3-1f4d-4c25-bf2d-347b4638e4e8"
   },
   "outputs": [],
   "source": [
    "!pip install Pillow==4.1.1\n",
    "!pip install PIL\n",
    "!pip install image\n",
    "import PIL.Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=64, shuffle=True)\n",
    "print(len(data_train), len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78656,
     "status": "ok",
     "timestamp": 1542554989777,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "LQmIjIkPUp3c",
    "outputId": "a5ca852d-c71f-4d68-8876-54e7f8e5e7fe"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "import torch.optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def accuracy(output,labels):\n",
    "  predictions = torch.argmax(output,dim=1)\n",
    "  correct = (predictions == labels).sum().cpu().numpy()\n",
    "  return correct / len(labels)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 159990,
     "status": "ok",
     "timestamp": 1542555075988,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "MdLpmJv_4nHG",
    "outputId": "3c9df9e3-4342-441b-99a0-050777d057ca"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "accuracies = []\n",
    "with torch.no_grad():\n",
    "  for itr,x in enumerate(test_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    y_pred = model.forward(data)\n",
    "    acc = accuracy(y_pred,labels)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "\n",
    "print('accuracy {:.2f}'.format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkhc7BihjPr5"
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lossf = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.95, nesterov=True)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12516
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 541564,
     "status": "ok",
     "timestamp": 1542557974550,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "QK0SU71D5XWP",
    "outputId": "6ca5cd76-5c9c-4684-fa14-00878694603c"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(6):\n",
    "  lr_scheduler.step()\n",
    "  for itr,x in enumerate(train_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    y_pred = model.forward(data)\n",
    "    \n",
    "    loss = lossf(y_pred,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Iteration {}, train accuracy {:.2f}, loss {:.4f}'.format(itr+epoch*len(train_loader),accuracy(y_pred,labels),loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 617980,
     "status": "ok",
     "timestamp": 1542558057641,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "NqWa3JbnMecc",
    "outputId": "4ff8a810-f21e-422d-c915-6ce24a6a416a"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "accuracies = []\n",
    "with torch.no_grad():\n",
    "  for itr,x in enumerate(test_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    y_pred = model.forward(data)\n",
    "    accuracies.append(accuracy(y_pred,labels))\n",
    "    \n",
    "\n",
    "print('accuracy {:.2f}'.format(np.mean(accuracies)))\n",
    "m_accuracy = np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qw9HgfOIZaWL"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'accuracy': m_accuracy,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model': model,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, \"/gdrive/My Drive/ML/CLTresnet18\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "СLTresnet18DZ5.ipynb",
   "provenance": [
    {
     "file_id": "1HcEfsMBHtOTkDKRcZiijemDsDqxGsjvQ",
     "timestamp": 1542546180740
    },
    {
     "file_id": "1Y7Z7jMnd-G_OJrERH_joKJPWESAUhoKR",
     "timestamp": 1542545972552
    },
    {
     "file_id": "1MTZZdn-bbaN7QT3HY0HQfZ0z7wXwODUu",
     "timestamp": 1542539775465
    },
    {
     "file_id": "124d4RlpABelaHUdav5_iox-7G-b0HfSX",
     "timestamp": 1542538648178
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
