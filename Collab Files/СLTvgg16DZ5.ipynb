{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12773,
     "status": "ok",
     "timestamp": 1542549905985,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "zrZs-4DcXW9O",
    "outputId": "95d04379-0cc8-4efd-af15-a6aff8ed4d6f"
   },
   "outputs": [],
   "source": [
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anY77OYKXlyU"
   },
   "outputs": [],
   "source": [
    " #!kill -9 -1 #(перезагрузка collab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35627,
     "status": "ok",
     "timestamp": 1542549943558,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "XbXzx6PPzlw9",
    "outputId": "51d14757-817e-474b-b1c7-c0d4227932b6"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9830,
     "status": "ok",
     "timestamp": 1542549966946,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "-n5ASkrIw9mz",
    "outputId": "144ad900-7f62-4e85-8a38-06d7a6d61d3c"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "model = models.vgg16(pretrained=True)\n",
    "num_classes = 20\n",
    "model.classifier[-1] = nn.Linear(in_features=4096, out_features=num_classes)\n",
    "nn.init.xavier_uniform_(model.classifier[-1].weight)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22656,
     "status": "ok",
     "timestamp": 1542550006391,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "wCCOEuAow9m8",
    "outputId": "8e02b6c6-f769-426c-8696-a914b8b2989c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262063
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47349,
     "status": "ok",
     "timestamp": 1542550058010,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "oWMiahTby9PV",
    "outputId": "eb6359f9-e28d-4621-cf1b-d09c8135361d"
   },
   "outputs": [],
   "source": [
    "!ls -la /gdrive/My\\ Drive/ML\n",
    "!cp /gdrive/My\\ Drive/ML/VOC2007.tar.gz .\n",
    "!ls .\n",
    "!tar -xvf VOC2007.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1jysm2rw9m_"
   },
   "outputs": [],
   "source": [
    "from  torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "IMAGE_FOLDER_ROOT = 'sample_data/VOC2007/VOC2007'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "data_train = ImageFolder(IMAGE_FOLDER_ROOT+'/trainval',transform=transforms.Compose([transforms.Resize(224),transforms.RandomCrop(224),transforms.ToTensor(),normalize]))\n",
    "data_test = ImageFolder(IMAGE_FOLDER_ROOT+'/test',transform=transforms.Compose([transforms.Resize(224),transforms.RandomCrop(224),transforms.ToTensor(),normalize]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 70344,
     "status": "ok",
     "timestamp": 1542550085421,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "JSMNLRXH3ZYE",
    "outputId": "13eff830-0105-4583-e825-d22b8b037fc0"
   },
   "outputs": [],
   "source": [
    "!pip install Pillow==4.1.1\n",
    "!pip install PIL\n",
    "!pip install image\n",
    "import PIL.Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=64, shuffle=True)\n",
    "print(len(data_train), len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1542552412726,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "LQmIjIkPUp3c",
    "outputId": "c6463acd-e2b9-48fe-e291-290aea8090f6"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "import torch.optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def accuracy(output,labels):\n",
    "  predictions = torch.argmax(output,dim=1)\n",
    "  correct = (predictions == labels).sum().cpu().numpy()\n",
    "  return correct / len(labels)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 474040,
     "status": "ok",
     "timestamp": 1542545298048,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "MdLpmJv_4nHG",
    "outputId": "6f804fd3-6168-4eef-b50f-cf6acdeda82d"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "accuracies = []\n",
    "with torch.no_grad():\n",
    "  for itr,x in enumerate(test_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    y_pred = model.forward(data)\n",
    "    acc = accuracy(y_pred,labels)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "\n",
    "print('accuracy {:.2f}'.format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkhc7BihjPr5"
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lossf = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 3 epochs\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12516
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 964657,
     "status": "ok",
     "timestamp": 1542553380701,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "QK0SU71D5XWP",
    "outputId": "6d463ba5-143e-468d-f942-aeb4e86cb83a"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(6):\n",
    "  lr_scheduler.step()\n",
    "  for itr,x in enumerate(train_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    y_pred = model.forward(data)\n",
    "    \n",
    "    loss = lossf(y_pred,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Iteration {}, train accuracy {:.2f}, loss {:.4f}'.format(itr+epoch*len(train_loader),accuracy(y_pred,labels),loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 147754,
     "status": "ok",
     "timestamp": 1542553536512,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "NqWa3JbnMecc",
    "outputId": "bb899cfa-b2b6-4395-9ada-b7db17c16562"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "accuracies = []\n",
    "with torch.no_grad():\n",
    "  for itr,x in enumerate(test_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    y_pred = model.forward(data)\n",
    "    accuracies.append(accuracy(y_pred,labels))\n",
    "    \n",
    "\n",
    "print('accuracy {:.2f}'.format(np.mean(accuracies)))\n",
    "model_accuracy = np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qw9HgfOIZaWL"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'accuracy': model_accuracy,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model': model,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, \"/gdrive/My Drive/ML/СLTvgg16\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "СLTvgg16DZ5.ipynb",
   "provenance": [
    {
     "file_id": "1Y7Z7jMnd-G_OJrERH_joKJPWESAUhoKR",
     "timestamp": 1542545972552
    },
    {
     "file_id": "1MTZZdn-bbaN7QT3HY0HQfZ0z7wXwODUu",
     "timestamp": 1542539775465
    },
    {
     "file_id": "124d4RlpABelaHUdav5_iox-7G-b0HfSX",
     "timestamp": 1542538648178
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
