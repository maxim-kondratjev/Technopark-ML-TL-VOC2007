{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transfer learning","version":"0.3.2","provenance":[{"file_id":"1oiosAoldwm1pE2VXdhLGE9Pt_TCKvifM","timestamp":1541003834575},{"file_id":"1eM1tsXaPw5uEN-crSeaJXsFYyNkLWZ1g","timestamp":1541003386975},{"file_id":"1Si37SXiFzTGplUhA17JTTg9A4GROBl4S","timestamp":1540998153474}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"OQEJRefYWzyq","colab_type":"code","colab":{}},"cell_type":"code","source":["# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YiucJGoB9hUJ","colab_type":"code","colab":{}},"cell_type":"code","source":["accelerator"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bEKZAjW1sk3E","colab_type":"code","colab":{}},"cell_type":"code","source":["#Google Colab имеет баг. нужно переставить пакеты. подробнее - http://forums.fast.ai/t/attributeerror-module-pil-image-has-no-attribute-register-extensions/10689/8\n","!pip install Pillow==4.0.0\n","!pip install PIL\n","!pip install image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iPU8wA71opai","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NVv1pgdzpWL5","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls -la /gdrive/My\\ Drive/ML"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h78SGA_oopbl","colab_type":"code","colab":{}},"cell_type":"code","source":["#скопируем архив с датасетом на виртуалку с GPU\n","!cp /gdrive/My\\ Drive/ML/dogscats_train.tar.gz .\n","!ls .\n","#Извлекаем в текущую папку. Данные появятся по пути sample_data/dogscats\n","!tar -xvf dogscats_train.tar.gz"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m6EjS4KKtlU9","colab_type":"text"},"cell_type":"markdown","source":["### torchvision.models\n","\n","Пакет models содержит в себе такие популярные архитектуры как:\n","\n","\n","1.  [AlexNet](https://arxiv.org/abs/1404.5997)\n","1. [VGG16](https://arxiv.org/abs/1409.1556)\n","1. [ResNet](https://arxiv.org/abs/1512.03385)\n","1. [SqueezeNet](https://arxiv.org/abs/1602.07360)\n","1. [DenseNet](https://arxiv.org/abs/1608.06993)\n","1. [Inception v3](https://arxiv.org/abs/1512.00567)\n","\n","\n","\n","---\n","\n","\n","\n","```\n","import torchvision.models as models\n","resnet18 = models.resnet18()\n","alexnet = models.alexnet()\n","vgg16 = models.vgg16()\n","vgg16 = models.vgg16_bn()\n","squeezenet = models.squeezenet1_0()\n","densenet = models.densenet161()\n","inception = models.inception_v3()\n","```\n","\n","\n","\n","---\n","\n","\n","\n","\n","\n"]},{"metadata":{"id":"C8wWNNuHX8L_","colab_type":"code","colab":{}},"cell_type":"code","source":["import torchvision.models as models\n","alexnet = models.alexnet()\n","alexnet"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FZvoeu7IYBJ2","colab_type":"text"},"cell_type":"markdown","source":[" PyTorch предоставлет предобученные модели через torch.utils.model_zoo. Их можно загрузить подав аргумент `pretrained=True`:\n"," \n","\n","---\n","```\n","import torchvision.models as models\n","resnet18 = models.resnet18(pretrained=True)\n","alexnet = models.alexnet(pretrained=True)\n","squeezenet = models.squeezenet1_0(pretrained=True)\n","vgg16 = models.vgg16(pretrained=True)\n","vgg16 = models.vgg16_bn(pretrained=True)\n","densenet = models.densenet161(pretrained=True)\n","inception = models.inception_v3(pretrained=True)\n","```\n","---\n","\n","# Важно!!!\n","\n","Большинство моделей имеет такие слой как Дорпаут и Batch Normalization.Не забывайте переключать режимы моделей с помощью model.train() для обучения или model.eval() вывода прогноза (инференса)\n","\n","Все предобученные модели ожидают на вход изображения нормализованные следующим образом: вектор из RGB  картинок размерностью (3 x H x W) где H и W = 224. При этом значения пикселей должны быть нормализованы до значений [0, 1] и затем применить mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225] Для нормализации входа можно использовать следующую трансформацию:\n","\n","```\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","```\n","P.S. `transforms.ToTensor()` меняет тип данных и также нормализует в интервал [0,1] [Docs](https://pytorch.org/docs/master/torchvision/transforms.html#torchvision.transforms.ToTensor)\n","\n"]},{"metadata":{"id":"TC8jtOEnYrmN","colab_type":"code","colab":{}},"cell_type":"code","source":["vgg = models.vgg16_bn(pretrained=True)\n","vgg"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pckj4FZM3fAg","colab_type":"text"},"cell_type":"markdown","source":["Обратим внимание, что изначально vgg16 была обучена на ImageNet и содержит 1000 классов. Для нашей задачи так много не нужно. Для осуществления дообучения (Transfer Learning) достаточно поменять последний слой изменив количество выходных нейронов.\n","\n","***Transfer Learning*** - это дообучение модели, которая хорошо выполняет похожую задачу. Т.е. мы переносим опыт модели из одной задачи на другую. Процесс дообучения называют ***тонкой настройкой модели (fine tuning)***\n","\n","Так давайте дообучим нашу модель"]},{"metadata":{"id":"HM_o1Qko37j2","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.nn as nn\n","#Классов 2 - кошка или собака\n","num_classes = 2\n","#Заменим последний слой на нужное количество нейронов\n","vgg.classifier[-1] = nn.Linear(in_features=4096, out_features=num_classes)\n","#FYI. У разных моделей по разному меняется последний слой. Например у resnet18 последний слой хранится в атрибуте resnet18.fc. Надо смотреть, будьте внимательны\n","vgg"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2LLM66Z5YtYE","colab_type":"code","colab":{}},"cell_type":"code","source":["from  torchvision.datasets import ImageFolder\n","import torchvision.transforms as transforms\n","import numpy as np\n","# Путь к набору данных с собаками\\кошками. Он может отличаться от введенного здесь.\n","# Ссылка нн поа папку с наборами данных - https://drive.google.com/open?id=1orjETr1xhw4hteDgDk40wYLq14TPtk1p\n","# Сохраните к себе на гугл диск и измените путь соответственно\n","IMAGE_FOLDER_ROOT = 'sample_data/dogscats/train'\n","\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","#Создадим датасет. Изменим размер до 256х256, применим случайное кадрирование изображения размером 224х224 (аугментация данных), в тензор и нормализуем\n","dataset = ImageFolder(IMAGE_FOLDER_ROOT,transform=transforms.Compose([transforms.Resize(256),transforms.RandomCrop(224),transforms.ToTensor(),normalize]))\n","\n","#Разделим папку на обучающую и валидационную выборку\n","validation_split = 0.25\n","indices = list(range(len(dataset)))\n","split = int(np.floor(validation_split * len(dataset)))\n","np.random.shuffle(indices)\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","#Создадим семплеры. \n","train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n","valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n","\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size=16, \n","                                           sampler=train_sampler)\n","validation_loader = torch.utils.data.DataLoader(dataset, batch_size=16,\n","                                                sampler=valid_sampler)\n","print(len(train_indices),len(val_indices))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dwEUMErSqwfe","colab_type":"text"},"cell_type":"markdown","source":["[ImageFolder](https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder) - это класс для чтения из папки изображений для созднаия собственного датасета. Будем его использовать для сегодняшнего задания\n","\n","**FYI** Если требуется более сложные виды обработки для данных, то следует создать свой класс, наследуя класс [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) перегрузив функции `__len__` и `__getitem__`. Пример наследования можно посмотреть [тут](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class)\n","\n","[SubsetRandomSampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.SubsetRandomSampler) - используется DataLoader'ом для определения стратегии выдачи примеров. В данном случае мы создали два Семплера для разделения выборки на обучающую и валидационную выборки "]},{"metadata":{"id":"T__QsKSu57rs","colab_type":"text"},"cell_type":"markdown","source":["Проверим качество модели до дообучения"]},{"metadata":{"id":"FZuP7-cw6B9E","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.optim\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def accuracy(output,labels):\n","  predictions = torch.argmax(output,dim=1)\n","  correct = (predictions == labels).sum().cpu().numpy()\n","  return correct / len(labels)\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","vgg.to(device)\n","vgg.eval()\n","\n","accuracies = []\n","with torch.no_grad():\n","  for itr,x in enumerate(validation_loader):\n","    data = x[0]\n","    labels = x[1]\n","\n","    data = data.to(device)\n","    labels = labels.to(device)\n","\n","    y_pred = vgg.forward(data)\n","    acc = accuracy(y_pred,labels)\n","    accuracies.append(acc)\n","    print(device,itr,'/',len(validation_loader),acc)\n","\n","\n","print('accuracy {:.2f}'.format(np.mean(accuracies)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0tCMk2cfsnIF","colab_type":"code","colab":{}},"cell_type":"code","source":["from torch.optim import lr_scheduler\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.SGD(vgg.parameters(), lr=0.001, momentum=0.9)\n","\n","# Decay LR by a factor of 0.1 every 7 epochs\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n","vgg.to(device)\n","vgg.train()\n","\n","\n","for epoch in range(1):\n","  for itr,x in enumerate(train_loader):\n","    data = x[0]\n","    labels = x[1]\n","\n","    optimizer.zero_grad()\n","\n","    data = data.to(device)\n","    labels = labels.to(device)\n","\n","    y_pred = vgg.forward(data)\n","    loss = criterion(y_pred,labels)\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    print('Iteration {}, train accuracy {:.2f}, loss {:.4f}'.format(itr+epoch*len(train_loader),accuracy(y_pred,labels),loss))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ysF5WOIs_gEF","colab_type":"text"},"cell_type":"markdown","source":["#### Проверим после дообучения"]},{"metadata":{"colab_type":"code","id":"-uCDk_z6_eV4","colab":{}},"cell_type":"code","source":["vgg.eval()\n","\n","accuracies = []\n","with torch.no_grad():\n","  for itr,x in enumerate(validation_loader):\n","    data = x[0]\n","    labels = x[1]\n","\n","    optimizer.zero_grad()\n","\n","    data = data.to(device)\n","    labels = labels.to(device)\n","\n","    y_pred = vgg.forward(data)\n","    accuracies.append(accuracy(y_pred,labels))\n","    \n","\n","print('accuracy {:.2f}'.format(np.mean(accuracies)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CjxXMY4z_0hr","colab_type":"text"},"cell_type":"markdown","source":["# Задание на семинар и на дом\n","\n","\n"," \n","1.  Дообучить модель на наборе данных PascalVOC2007. Модель может быть любой из пакета **torchvision.models**. \n","2.  Достичь 70% средней точности \n","3.  Создать текстовую ячейку с точностями по каждому классу\n","\n"]},{"metadata":{"id":"SdIXPGvhAQOT","colab_type":"code","colab":{}},"cell_type":"code","source":["##TRAIN_ME_HERE### "],"execution_count":0,"outputs":[]}]}