{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11169,
     "status": "ok",
     "timestamp": 1542184896677,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "2vpLsvwUYHup",
    "outputId": "dbad27aa-8c1b-4173-a877-ea3f280f28b5"
   },
   "outputs": [],
   "source": [
    "#memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36610,
     "status": "ok",
     "timestamp": 1542184969687,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "XbXzx6PPzlw9",
    "outputId": "6de90443-fb44-4e8e-c8b6-80813b3344d8"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10537,
     "status": "ok",
     "timestamp": 1542185091133,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "-n5ASkrIw9mz",
    "outputId": "a8150924-5e71-4ae5-c88a-8b24ea58820b"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wHgcyijr0tBm"
   },
   "source": [
    "(fc): Linear(in_features=4096, out_features=1000, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 941,
     "status": "ok",
     "timestamp": 1542185095355,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "fSzib0YAw9m4",
    "outputId": "d5b0105e-31b4-47d2-ec5f-cb255e6db82c"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "num_classes = 20\n",
    "model.classifier[-1] = nn.Linear(in_features=4096, out_features=num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYONd0iE0yt4"
   },
   "source": [
    "(fc): Linear(in_features=4096, out_features=20, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25318,
     "status": "ok",
     "timestamp": 1542185123852,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "wCCOEuAow9m8",
    "outputId": "6d164759-06e8-43c4-a343-548688f8bba9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261996
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45920,
     "status": "ok",
     "timestamp": 1542185180133,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "oWMiahTby9PV",
    "outputId": "f84443ea-ac31-4b72-e333-d37dc36d51cd"
   },
   "outputs": [],
   "source": [
    "!ls -la /gdrive/My\\ Drive/ML\n",
    "!cp /gdrive/My\\ Drive/ML/VOC2007.tar.gz .\n",
    "!ls .\n",
    "!tar -xvf VOC2007.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1jysm2rw9m_"
   },
   "outputs": [],
   "source": [
    "from  torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "IMAGE_FOLDER_ROOT = 'sample_data/VOC2007/VOC2007'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MGpHc9S1kCN"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "data_train = ImageFolder(IMAGE_FOLDER_ROOT+'/trainval',transform=transforms.Compose([transforms.Resize(224),transforms.RandomCrop(224),transforms.ToTensor(),normalize]))\n",
    "data_test = ImageFolder(IMAGE_FOLDER_ROOT+'/test',transform=transforms.Compose([transforms.Resize(224),transforms.RandomCrop(224),transforms.ToTensor(),normalize]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1380,
     "status": "ok",
     "timestamp": 1542185564632,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "JSMNLRXH3ZYE",
    "outputId": "75504bba-d80b-4e3b-db2c-7c921bdb51b7"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=16, shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=16, shuffle=True, num_workers=8)\n",
    "print(len(data_train), len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15346,
     "status": "ok",
     "timestamp": 1542185231548,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "whXdC2xZ7qYA",
    "outputId": "0b71ac02-eccb-411e-a334-7a802e68901f"
   },
   "outputs": [],
   "source": [
    "!pip install Pillow==4.1.1\n",
    "!pip install PIL\n",
    "!pip install image\n",
    "import PIL.Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4611,
     "status": "ok",
     "timestamp": 1542185236226,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "LQmIjIkPUp3c",
    "outputId": "0de8f495-da3f-4a3f-9d44-066cf717a6b8"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "import torch.optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def accuracy(output,labels):\n",
    "  predictions = torch.argmax(output,dim=1)\n",
    "  correct = (predictions == labels).sum().cpu().numpy()\n",
    "  return correct / len(labels)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2692,
     "status": "error",
     "timestamp": 1542185572687,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "QK0SU71D5XWP",
    "outputId": "dfe77004-361c-4d04-f2e4-3264ff0c79c8"
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lossf = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(3):\n",
    "  for itr,x in enumerate(train_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    y_pred = model.forward(data)\n",
    "\n",
    "    loss = lossf(y_pred,labels)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    print('Iteration {}, train accuracy {:.2f}, loss {:.4f}'.format(itr+epoch*len(train_loader),accuracy(y_pred,labels),loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1542185589051,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "nDzIffe1bIFg",
    "outputId": "4b48f9c4-7ff4-4ac1-f3b0-4e0efb2da843"
   },
   "outputs": [],
   "source": [
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NqWa3JbnMecc"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "accuracies = []\n",
    "with torch.no_grad():\n",
    "  for itr,x in enumerate(test_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    y_pred = model.forward(data)\n",
    "    accuracies.append(accuracy(y_pred,labels))\n",
    "    \n",
    "\n",
    "print('accuracy {:.2f}'.format(np.mean(accuracies)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vggDZ5.ipynb",
   "provenance": [
    {
     "file_id": "124d4RlpABelaHUdav5_iox-7G-b0HfSX",
     "timestamp": 1541705518974
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
