{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10896,
     "status": "ok",
     "timestamp": 1542281944420,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "zrZs-4DcXW9O",
    "outputId": "24723c65-c48a-4e46-b442-2cf44107c60c"
   },
   "outputs": [],
   "source": [
    "# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 50667,
     "status": "ok",
     "timestamp": 1542281995881,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "XbXzx6PPzlw9",
    "outputId": "73d8b3cc-413d-42b6-8965-ba6bfa28bb41"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2917,
     "status": "ok",
     "timestamp": 1542282644330,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "-n5ASkrIw9mz",
    "outputId": "26e7818f-ed47-4e3c-9d5e-80843ecdffd2"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "model = models.alexnet(pretrained=True)\n",
    "num_classes = 20\n",
    "model.classifier[-1] = nn.Linear(in_features=4096, out_features=num_classes)\n",
    "nn.init.xavier_uniform(model.classifier[-1].weight)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86976,
     "status": "ok",
     "timestamp": 1542282096301,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "wCCOEuAow9m8",
    "outputId": "313cee1a-0789-48c9-9ea3-774287731d9a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261996
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43021,
     "status": "ok",
     "timestamp": 1542282139369,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "oWMiahTby9PV",
    "outputId": "b4f5a71c-cf52-40af-f839-164ffa4997f9"
   },
   "outputs": [],
   "source": [
    "!ls -la /gdrive/My\\ Drive/ML\n",
    "!cp /gdrive/My\\ Drive/ML/VOC2007.tar.gz .\n",
    "!ls .\n",
    "!tar -xvf VOC2007.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1jysm2rw9m_"
   },
   "outputs": [],
   "source": [
    "from  torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "IMAGE_FOLDER_ROOT = 'sample_data/VOC2007/VOC2007'\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "data_train = ImageFolder(IMAGE_FOLDER_ROOT+'/trainval',transform=transforms.Compose([transforms.Resize(224),transforms.RandomCrop(224),transforms.ToTensor(),normalize]))\n",
    "data_test = ImageFolder(IMAGE_FOLDER_ROOT+'/test',transform=transforms.Compose([transforms.Resize(224),transforms.RandomCrop(224),transforms.ToTensor(),normalize]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13857,
     "status": "ok",
     "timestamp": 1542282170493,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "JSMNLRXH3ZYE",
    "outputId": "99014b36-0bf9-4eda-c5d6-a79536dc7310"
   },
   "outputs": [],
   "source": [
    "!pip install Pillow==4.1.1\n",
    "!pip install PIL\n",
    "!pip install image\n",
    "import PIL.Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=128, shuffle=True)\n",
    "print(len(data_train), len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1542282762502,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "LQmIjIkPUp3c",
    "outputId": "81371a6b-bafc-4d6f-eae2-c0c833925011"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "import torch.optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def accuracy(output,labels):\n",
    "  predictions = torch.argmax(output,dim=1)\n",
    "  correct = (predictions == labels).sum().cpu().numpy()\n",
    "  return correct / len(labels)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88407,
     "status": "ok",
     "timestamp": 1542282896720,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "MdLpmJv_4nHG",
    "outputId": "49bf51d3-2b40-4a5d-e911-4e059c0de069"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "accuracies = []\n",
    "with torch.no_grad():\n",
    "  for itr,x in enumerate(test_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    y_pred = model.forward(data)\n",
    "    acc = accuracy(y_pred,labels)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "\n",
    "print('accuracy {:.2f}'.format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1542282673816,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "tkhc7BihjPr5",
    "outputId": "f53d1642-81ee-43c4-8b5a-c57850f64eda"
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lossf = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52097
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1797309,
     "status": "ok",
     "timestamp": 1542287549453,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "QK0SU71D5XWP",
    "outputId": "2c1fc383-b387-449d-f60d-158785db8c57"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(50):\n",
    "  lr_scheduler.step()\n",
    "  for itr,x in enumerate(train_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    y_pred = model.forward(data)\n",
    "    \n",
    "    loss = lossf(y_pred,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Iteration {}, train accuracy {:.2f}, loss {:.4f}'.format(itr+epoch*len(train_loader),accuracy(y_pred,labels),loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 81313,
     "status": "ok",
     "timestamp": 1542287636891,
     "user": {
      "displayName": "maximka rulet",
      "photoUrl": "",
      "userId": "16979091393164751145"
     },
     "user_tz": -180
    },
    "id": "NqWa3JbnMecc",
    "outputId": "1c30bfad-dc79-4531-af29-c9da79ea792e"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "accuracies = []\n",
    "with torch.no_grad():\n",
    "  for itr,x in enumerate(test_loader):\n",
    "    data = x[0]\n",
    "    labels = x[1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    y_pred = model.forward(data)\n",
    "    accuracies.append(accuracy(y_pred,labels))\n",
    "    \n",
    "\n",
    "print('accuracy {:.2f}'.format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qw9HgfOIZaWL"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'model': model,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, \"/gdrive/My Drive/ML/alexnet\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "alexnetDZ5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
